{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook recorre los archivos html de la carpeta `./data/raw`, y exporta de ahi el js del cuatrimestre\n",
    "\n",
    "Ese `horarios.js` hay que ponerlo en la carpeta src/data\n",
    "\n",
    "La carpeta data tiene que tener un archivo html por **cada carrera**\n",
    "\n",
    "El html se consigue de la siguiente manera\n",
    "- Loggearse al SIU, ir a \"Reportes\" > \"Oferta de comisiones\"\n",
    "- Conseguir el HTML de ese sitio (CTRL+U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "replacements = {\n",
    "    r'\\\"': r'\"',\n",
    "    r'<\\/': r'</',\n",
    "    r'\\n': '',\n",
    "    '\\n': '',\n",
    "    '\\t': '',\n",
    "    r'\\t': '',\n",
    "    'á':'a',\n",
    "    'é':'e',\n",
    "    'í':'i',\n",
    "    'ó':'o',\n",
    "    'ú':'u',\n",
    "    'Á':'A',\n",
    "    'É':'E',\n",
    "    'Í':'I',\n",
    "    'Ó':'O',\n",
    "    'Ú':'U'\n",
    "}\n",
    "\n",
    "\n",
    "for f in sorted(os.listdir('raw'), key=os.path.getmtime):\n",
    "    with open('raw/'+f, 'r') as fsub:\n",
    "        print(f, end=\"\")\n",
    "        txt = fsub.read()\n",
    "        txt = txt.encode('iso-8859-1').decode('unicode_escape')\n",
    "        for k,v in replacements.items():\n",
    "            txt = txt.replace(k,v)\n",
    "        start = txt.find(\"kernel.renderer.on_arrival({\")\n",
    "        end = txt.find(\"})\", start)\n",
    "        content = txt.find('content', start, end)\n",
    "        contentstart = txt.find('\"<', content)\n",
    "        contentend = txt.find('>\",', contentstart)\n",
    "        txt = txt[contentstart+1:contentend+1]\n",
    "        soup = BeautifulSoup(txt, 'html.parser')\n",
    "        ultimocuatri = soup.find_all('div', {'class': 'js-recuadro_periodo'})[-1]\n",
    "        with open('clean/'+f, 'wb') as newf:\n",
    "            newf.write(ultimocuatri.prettify(\"utf-8\"))\n",
    "        print(\" -> clean/\" + f)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import re\n",
    "import json\n",
    "\n",
    "REGEX = r'(.*) (\\(\\d\\d\\d\\d\\))'\n",
    "materia_regex = re.compile(REGEX)\n",
    "DIAS_DE_LA_HERMOSA_SEMANA = [\"Domingo\", \"Lunes\", \"Martes\", \"Miercoles\", \"Jueves\", \"Viernes\", \"Sabado\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_ids_materias(soup):\n",
    "    codigos_materias = []\n",
    "    actividades = soup.find_all('div', {'class': 'js-recuadro_actividad'})\n",
    "    for act in actividades:\n",
    "        nombre, codigo = materia_regex.search(act.get('actividad')).groups()\n",
    "        codigo = re.sub('\\(|\\)', \"\", codigo)\n",
    "        codigos_materias.append(codigo)\n",
    "    return codigos_materias\n",
    "\n",
    "soup = BeautifulSoup(open(\"clean/informatica.html\"), \"html.parser\")\n",
    "get_ids_materias(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_comisiones(soup):\n",
    "    ids_comisiones = []\n",
    "    comisiones_soup = soup.find_all('table', {'class': 'comision'})\n",
    "    for comision in comisiones_soup:\n",
    "        comision_id = comision.get('comision')\n",
    "        ids_comisiones.append(comision_id)\n",
    "    return ids_comisiones\n",
    "\n",
    "def get_materias(soup):\n",
    "    materias = []\n",
    "    actividades = soup.find_all('div', {'class': 'js-recuadro_actividad'})\n",
    "    for act in actividades:\n",
    "        nombre, codigo = materia_regex.search(act.get('actividad')).groups()\n",
    "        codigo = re.sub('\\(|\\)', \"\", codigo)\n",
    "        ids_comisiones = get_ids_comisiones(act)\n",
    "        \n",
    "        materias.append({\n",
    "            \"codigo\": codigo,\n",
    "            \"nombre\": nombre,\n",
    "            \"cursos\": ids_comisiones\n",
    "        })\n",
    "        \n",
    "    return materias\n",
    "\n",
    "soup = BeautifulSoup(open(\"clean/informatica.html\"), \"html.parser\")\n",
    "get_materias(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comision(soup, codigo):\n",
    "    comision_soup = soup.find('table', {'comision': codigo})\n",
    "    docentes = comision_soup.get('docentes')\n",
    "    comision_id = comision_soup.get('comision')\n",
    "    clases = []\n",
    "\n",
    "    for dia_semana_soup in comision_soup.find_all('tr', {'class': ['js-dia']}):\n",
    "        dia_semana = dia_semana_soup.get('dia_sem')\n",
    "        horas_soup = dia_semana_soup.find('td', text=re.compile(r'\\d\\d\\:\\d\\d'))\n",
    "        if not horas_soup:\n",
    "            continue\n",
    "        horas = horas_soup.contents[0]\n",
    "        inicio, fin = horas.split(' a ')\n",
    "\n",
    "        clases.append({'dia': DIAS_DE_LA_HERMOSA_SEMANA.index(dia_semana), 'inicio': inicio, 'fin': fin})\n",
    "\n",
    "    return {\n",
    "        \"docentes\": docentes,\n",
    "        \"codigo\": codigo,\n",
    "        \"clases\": clases\n",
    "    }\n",
    "\n",
    "soup = BeautifulSoup(open(\"clean/informatica.html\"), \"html.parser\")\n",
    "get_comision(soup, \"31265\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "NOMBRES = {\n",
    "    \"clean/informatica.html\": \"Ingeniería en Informática\",\n",
    "    \"clean/civil.html\": \"Ingeniería Civil\",\n",
    "    \"clean/industrial.html\": \"Ingeniería Industrial\",\n",
    "    \"clean/mecanica.html\": \"Ingeniería Mecánica\",\n",
    "    \"clean/quimica.html\": \"Ingeniería Química\",\n",
    "    \"clean/sistemas.html\": \"Licenciatura en Análisis de Sistemas\",\n",
    "    \"clean/sistemas86.html\": \"Licenciatura en Análisis de Sistemas (Plan viejo)\",\n",
    "    \"clean/electronica.html\": \"Ingeniería Electrónica\",\n",
    "    \"clean/alimentos.html\": \"Ingeniería de Alimentos\",\n",
    "    \"clean/agrimensura.html\": \"Ingeniería en Agrimensura\",\n",
    "    \"clean/naval-mecanica.html\": \"Ingeniería Naval y Mecánica\",\n",
    "    \"clean/petroleo.html\": \"Ingeniería en Petroleo\",\n",
    "    \"clean/electricista.html\": \"Ingeniería Electricista\"\n",
    "}\n",
    "\n",
    "carreras = []\n",
    "codigos_materias_agregadas = []\n",
    "materias = []\n",
    "codigos_comisiones_agregadas = []\n",
    "comisiones = []\n",
    "\n",
    "for f in sorted(os.listdir('clean'), key=os.path.getmtime, reverse=True):\n",
    "    f = 'clean/'+f\n",
    "    soup = BeautifulSoup(open(f), \"html.parser\")\n",
    "\n",
    "    carreras.append({\n",
    "        \"nombre\": NOMBRES[f],\n",
    "        'materias': get_ids_materias(soup)\n",
    "    })\n",
    "    \n",
    "    materias_carrera = get_materias(soup)\n",
    "    materias_carrera = [x for x in materias_carrera if x['codigo'] not in codigos_materias_agregadas]\n",
    "    for m in materias_carrera:\n",
    "        codigos_materias_agregadas.append(m['codigo'])\n",
    "        comisiones_materia = m.get('cursos')\n",
    "        comisiones_materia = [x for x in comisiones_materia if x not in codigos_comisiones_agregadas]\n",
    "        for c in comisiones_materia:\n",
    "            codigos_comisiones_agregadas.append(c)\n",
    "            comisiones.append(get_comision(soup, c))\n",
    "            \n",
    "        comisiones_sin_clases = filter(lambda x: not x['clases'], comisiones)\n",
    "        comisiones_sin_clases_codigos = map(lambda x: x['codigo'], comisiones_sin_clases)\n",
    "        m['cursos'] = list(filter(lambda x: x not in comisiones_sin_clases_codigos, m['cursos']))\n",
    "    \n",
    "    comisiones = list(filter(lambda x: x['clases'], comisiones))\n",
    "    materias.extend(materias_carrera) \n",
    "    \n",
    "obj = {\n",
    "    \"cuatrimestre\": \"2021C1\",\n",
    "    \"timestamp\": str(datetime.datetime.now()),\n",
    "    \"carreras\": sorted(carreras, key=lambda x: x['nombre']),\n",
    "    \"materias\": sorted(materias, key=lambda x: x['codigo']),\n",
    "    \"cursos\": sorted(comisiones, key=lambda x: x['codigo'])\n",
    "}\n",
    "\n",
    "obj_dump = json.dumps(obj, indent=2, ensure_ascii=False)        \n",
    "\n",
    "with open('horarios.js', 'w') as fw:\n",
    "    fw.write(\"export const data = \")\n",
    "    fw.write(obj_dump)\n",
    "\n",
    "print(obj_dump)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
